{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78189db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "36b530c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = '../../ellias_test'\n",
    "RESIZED_PATH = IMAGES_PATH + \"/\" + \"resized\"\n",
    "\n",
    "MODEL_PATH = \"../models/100ep_200k_v2/cp.h5\"\n",
    "METADATA_PATH = './Ressources/list_attr_celeba.csv'\n",
    "excluded_labels = [\"Arched_Eyebrows\",\"Attractive\",\"Blurry\",\"Double_Chin\",\"Narrow_Eyes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93c1b38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(dir_path):\n",
    "    cnt = 0\n",
    "    for file in os.listdir(dir_path):\n",
    "        image_path = dir_path + \"/\" + file\n",
    "\n",
    "        img = Image.open(image_path) \n",
    "        img = img.resize((224,224))\n",
    "\n",
    "        if not os.path.exists(RESIZED_PATH):\n",
    "            os.makedirs(RESIZED_PATH)\n",
    "\n",
    "        img.save(RESIZED_PATH+\"/\"+file)\n",
    "\n",
    "        cnt += 1\n",
    "\n",
    "    print(\"Resize of \" + str(cnt) + \" images done !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f876c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_images(dir_path):\n",
    "    images = []\n",
    "    for file in os.listdir(dir_path):\n",
    "        images.append(file)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf90e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize(IMAGES_PATH)\n",
    "images = list_images(RESIZED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "88bba2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old = pd.read_csv(METADATA_PATH)\n",
    "\n",
    "y = []\n",
    "for row in df_old.iterrows():\n",
    "    sub_y = []\n",
    "    for i in range(1,len(row[1])) :\n",
    "        if (int(row[1][i])==1) and (df_old.columns.values[i] not in excluded_labels):\n",
    "            sub_y.append(df_old.columns.values[i])\n",
    "    y.append(sub_y)\n",
    "    \n",
    "df = pd.DataFrame(list(zip(list(df_old[df_old.columns[0]]), y)),\n",
    "               columns =['image_path', 'tags'])\n",
    "\n",
    "all_labels = [] \n",
    "for labels in df['tags'].values.tolist():\n",
    "    for label in labels:\n",
    "        all_labels.append(label)\n",
    "        \n",
    "unique_labels = list(np.unique(all_labels))\n",
    "#print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f186dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2*((p*r)/(p+r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f900790a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération du modèle\n"
     ]
    }
   ],
   "source": [
    "print(\"Récupération du modèle\")\n",
    "model = load_model(MODEL_PATH, custom_objects={\"f1\": f1, \"recall\": recall,\"precision\": precision}, compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae5b5ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images resized !\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "000001.jpg\n",
      "Best labels : \n",
      "['Bangs 72.2%', 'Blond_Hair 98.3%', 'Heavy_Makeup 93.1%', 'High_Cheekbones 57.6%', 'Mouth_Slightly_Open 65.7%', 'No_Beard 99.8%', 'Smiling 47.6%', 'Wavy_Hair 85.8%', 'Wearing_Lipstick 98.7%', 'Wearing_Necklace 46.4%', 'Young 86.1%']\n",
      "000002.jpg\n",
      "Best labels : \n",
      "['Mouth_Slightly_Open 58.0%', 'No_Beard 82.4%', 'Smiling 44.2%', 'Wearing_Lipstick 40.8%', 'Young 57.5%']\n",
      "000003.jpg\n",
      "Best labels : \n",
      "['Gray_Hair 41.4%', 'Male 51.0%', 'Mouth_Slightly_Open 55.1%', 'No_Beard 84.5%', 'Young 57.7%']\n",
      "000004.jpg\n",
      "Best labels : \n",
      "['Bangs 76.0%', 'Male 51.1%', 'No_Beard 53.7%', 'Pointy_Nose 41.2%', 'Wavy_Hair 55.4%', 'Wearing_Earrings 56.6%', 'Young 46.4%']\n",
      "000005.jpg\n",
      "Best labels : \n",
      "['Heavy_Makeup 71.3%', 'High_Cheekbones 54.8%', 'Mouth_Slightly_Open 49.3%', 'No_Beard 84.7%', 'Oval_Face 53.9%', 'Pointy_Nose 44.3%', 'Smiling 54.3%', 'Wavy_Hair 51.0%', 'Wearing_Lipstick 78.7%', 'Young 93.7%']\n",
      "000006.jpg\n",
      "Best labels : \n",
      "['Blond_Hair 55.7%', 'Brown_Hair 57.2%', 'Heavy_Makeup 90.0%', 'High_Cheekbones 70.9%', 'Mouth_Slightly_Open 63.4%', 'No_Beard 96.5%', 'Oval_Face 40.8%', 'Pointy_Nose 61.6%', 'Rosy_Cheeks 65.3%', 'Smiling 72.2%', 'Wavy_Hair 94.0%', 'Wearing_Earrings 60.3%', 'Wearing_Lipstick 94.7%', 'Wearing_Necklace 48.2%', 'Young 90.9%']\n",
      "000007.jpg\n",
      "Best labels : \n",
      "['5_o_Clock_Shadow 63.5%', 'Bags_Under_Eyes 42.3%', 'Big_Nose 41.9%', 'Black_Hair 55.7%', 'Heavy_Makeup 41.8%', 'Male 67.9%', 'Mouth_Slightly_Open 53.8%', 'No_Beard 70.1%', 'Oval_Face 52.3%', 'Pointy_Nose 56.9%', 'Smiling 57.8%', 'Young 76.5%']\n",
      "000008.jpg\n",
      "Best labels : \n",
      "['Black_Hair 46.7%', 'Bushy_Eyebrows 50.4%', 'High_Cheekbones 58.2%', 'Male 54.8%', 'Mouth_Slightly_Open 48.3%', 'No_Beard 70.8%', 'Oval_Face 53.4%', 'Pointy_Nose 42.0%', 'Smiling 67.7%', 'Young 74.4%']\n",
      "000009.jpg\n",
      "Best labels : \n",
      "['Big_Lips 42.6%', 'Heavy_Makeup 50.8%', 'High_Cheekbones 68.4%', 'Mouth_Slightly_Open 48.2%', 'No_Beard 68.4%', 'Smiling 71.2%', 'Wearing_Earrings 47.1%', 'Wearing_Lipstick 84.0%', 'Young 82.6%']\n",
      "000010.jpg\n",
      "Best labels : \n",
      "['Brown_Hair 43.3%', 'Heavy_Makeup 62.5%', 'High_Cheekbones 74.1%', 'Mouth_Slightly_Open 60.0%', 'No_Beard 90.3%', 'Oval_Face 54.6%', 'Smiling 53.8%', 'Wavy_Hair 43.9%', 'Wearing_Lipstick 76.7%', 'Young 90.4%']\n",
      "000011.jpg\n",
      "Best labels : \n",
      "['Black_Hair 90.3%', 'Heavy_Makeup 40.1%', 'No_Beard 93.8%', 'Wearing_Lipstick 68.6%', 'Young 98.6%']\n",
      "000012.jpg\n",
      "Best labels : \n",
      "['5_o_Clock_Shadow 57.0%', 'Bags_Under_Eyes 55.5%', 'Big_Nose 61.7%', 'Black_Hair 49.9%', 'Bushy_Eyebrows 40.4%', 'Male 97.7%', 'Mouth_Slightly_Open 51.6%', 'Smiling 59.5%', 'Straight_Hair 46.9%', 'Wearing_Necktie 51.8%', 'Young 63.7%']\n",
      "000013.jpg\n",
      "Best labels : \n",
      "['Bags_Under_Eyes 57.5%', 'Big_Nose 49.5%', 'High_Cheekbones 69.3%', 'Male 65.1%', 'Mouth_Slightly_Open 61.5%', 'No_Beard 75.0%', 'Oval_Face 58.0%', 'Smiling 69.4%', 'Young 73.0%']\n",
      "000014.jpg\n",
      "Best labels : \n",
      "['Bags_Under_Eyes 48.5%', 'Big_Nose 57.4%', 'Black_Hair 91.0%', 'Bushy_Eyebrows 43.1%', 'Chubby 43.7%', 'High_Cheekbones 50.3%', 'Male 89.2%', 'Mouth_Slightly_Open 80.2%', 'No_Beard 56.7%', 'Oval_Face 49.8%', 'Smiling 81.0%', 'Young 59.7%']\n",
      "000015.jpg\n",
      "Best labels : \n",
      "['Blond_Hair 44.5%', 'Heavy_Makeup 42.9%', 'High_Cheekbones 60.0%', 'Mouth_Slightly_Open 66.7%', 'No_Beard 95.3%', 'Oval_Face 47.1%', 'Smiling 51.7%', 'Young 78.8%']\n",
      "000016.jpg\n",
      "Best labels : \n",
      "['Bags_Under_Eyes 40.9%', 'Bushy_Eyebrows 40.9%', 'Male 74.0%', 'Mouth_Slightly_Open 45.2%', 'No_Beard 73.7%', 'Smiling 48.1%']\n",
      "000017.jpg\n",
      "Best labels : \n",
      "['Male 55.5%', 'Mouth_Slightly_Open 50.9%', 'No_Beard 74.7%', 'Smiling 53.4%', 'Straight_Hair 43.9%', 'Young 78.1%']\n",
      "000018.jpg\n",
      "Best labels : \n",
      "['Blond_Hair 79.5%', 'Heavy_Makeup 77.9%', 'High_Cheekbones 71.2%', 'Mouth_Slightly_Open 54.5%', 'No_Beard 89.3%', 'Oval_Face 56.8%', 'Pointy_Nose 47.0%', 'Rosy_Cheeks 40.9%', 'Smiling 62.2%', 'Wavy_Hair 67.2%', 'Wearing_Earrings 41.3%', 'Wearing_Lipstick 90.2%', 'Young 81.2%']\n",
      "000019.jpg\n",
      "Best labels : \n",
      "['Blond_Hair 99.5%', 'Heavy_Makeup 93.5%', 'High_Cheekbones 81.0%', 'Mouth_Slightly_Open 66.8%', 'No_Beard 99.4%', 'Oval_Face 66.1%', 'Pointy_Nose 68.8%', 'Rosy_Cheeks 44.2%', 'Smiling 70.0%', 'Wavy_Hair 47.6%', 'Wearing_Lipstick 98.6%', 'Wearing_Necklace 76.2%', 'Young 74.6%']\n",
      "000020.jpg\n",
      "Best labels : \n",
      "['Bags_Under_Eyes 56.8%', 'Big_Nose 60.5%', 'High_Cheekbones 55.0%', 'Male 82.4%', 'Mouth_Slightly_Open 43.4%', 'No_Beard 59.4%', 'Sideburns 42.8%']\n"
     ]
    }
   ],
   "source": [
    "# TEST SUR UN DOSSIER D'IMAGES\n",
    "\n",
    "predictions =  []\n",
    "images_path = []\n",
    "labels_images = []\n",
    "best_labels = []\n",
    "seuil_confiance = 40\n",
    "for file in os.listdir(RESIZED_PATH):\n",
    "    f_img = RESIZED_PATH+\"/\"+file\n",
    "\n",
    "    #load image\n",
    "    my_image = load_img(f_img, target_size=(224, 224))\n",
    "    #preprocess the image\n",
    "    my_image = img_to_array(my_image)\n",
    "    my_image = my_image.reshape((1, my_image.shape[0], my_image.shape[1], my_image.shape[2]))\n",
    "    my_image = preprocess_input(my_image)\n",
    "\n",
    "    #make the prediction<br>\n",
    "    pred_values = model.predict(my_image)\n",
    "    predictions.append(pred_values)\n",
    "    images_path.append(file)\n",
    "\n",
    "    #enregistre les meilleurs labels\n",
    "    best = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(len(pred_values[0])):\n",
    "        if pred_values[0][i]*100 > seuil_confiance :\n",
    "            best.append(unique_labels[i] + \" %.1f\" % (pred_values[0][i]*100) + \"%\")\n",
    "        labels.append(unique_labels[i] + \" %.1f\" % (pred_values[0][i]*100) + \"%\")\n",
    "\n",
    "    best_labels.append(best)\n",
    "    labels_images.append(labels)\n",
    "\n",
    "\n",
    "for image in range(len(images_path)):\n",
    "    print(images_path[image])\n",
    "    print(\"Best labels : \")\n",
    "    print(best_labels[image])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
